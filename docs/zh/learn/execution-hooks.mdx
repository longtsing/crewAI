---
title: 执行钩子概述
description: 理解和使用 CrewAI 中的执行钩子，对代理操作进行细粒度控制
mode: "wide"
---

执行钩子提供对 CrewAI 代理运行时行为的细粒度控制。与在团队执行前后运行的启动钩子不同，执行钩子在代理执行期间拦截特定操作，允许您修改行为、实现安全检查并添加全面的监控。

## 执行钩子的类型

CrewAI 提供两个主要类别的执行钩子：

### 1. [LLM 调用钩子](/learn/llm-hooks)

控制和监控语言模型交互：
- **LLM 调用前**：修改提示、验证输入、实现审批门
- **LLM 调用后**：转换响应、清理输出、更新对话历史

**使用场景：**
- 迭代限制
- 成本跟踪和令牌使用监控
- 响应清理和内容过滤
- LLM 调用的人工审批
- 添加安全准则或上下文
- 调试日志记录和请求/响应检查

[查看 LLM 钩子文档 →](/learn/llm-hooks)

### 2. [工具调用钩子](/learn/tool-hooks)

控制和监控工具执行：
- **工具调用前**：修改输入、验证参数、阻止危险操作
- **工具调用后**：转换结果、清理输出、记录执行细节

**使用场景：**
- 破坏性操作的安全护栏
- 敏感操作的人工审批
- 输入验证和清理
- 结果缓存和速率限制
- 工具使用分析
- 调试日志记录和监控

[查看工具钩子文档 →](/learn/tool-hooks)

## 钩子注册方法

### 1. 基于装饰器的钩子（推荐）

注册钩子最简洁且最 Pythonic 的方式：

```python
from crewai.hooks import before_llm_call, after_llm_call, before_tool_call, after_tool_call

@before_llm_call
def limit_iterations(context):
    """通过限制迭代次数防止无限循环。"""
    if context.iterations > 10:
        return False  # 阻止执行
    return None

@after_llm_call
def sanitize_response(context):
    """从 LLM 响应中移除敏感数据。"""
    if "API_KEY" in context.response:
        return context.response.replace("API_KEY", "[已编辑]")
    return None

@before_tool_call
def block_dangerous_tools(context):
    """阻止破坏性操作。"""
    if context.tool_name == "delete_database":
        return False  # 阻止执行
    return None

@after_tool_call
def log_tool_result(context):
    """记录工具执行。"""
    print(f"工具 {context.tool_name} 完成")
    return None
```

### 2. 团队范围钩子

仅将钩子应用于特定的团队实例：

```python
from crewai import CrewBase
from crewai.project import crew
from crewai.hooks import before_llm_call_crew, after_tool_call_crew

@CrewBase
class MyProjCrew:
    @before_llm_call_crew
    def validate_inputs(self, context):
        # 仅适用于此团队
        print(f"LLM 调用在 {self.__class__.__name__}")
        return None

    @after_tool_call_crew
    def log_results(self, context):
        # 团队特定日志记录
        print(f"工具结果: {context.tool_result[:50]}...")
        return None

    @crew
    def crew(self) -> Crew:
        return Crew(
            agents=self.agents,
            tasks=self.tasks,
            process=Process.sequential
        )
```

## 钩子执行流程

### LLM 调用流程

```
代理需要调用 LLM
    ↓
[LLM 调用前钩子执行]
    ├→ 钩子 1: 验证迭代次数
    ├→ 钩子 2: 添加安全上下文
    └→ 钩子 3: 记录请求
    ↓
如果任何钩子返回 False:
    ├→ 阻止 LLM 调用
    └→ 抛出 ValueError
    ↓
如果所有钩子返回 True/None:
    ├→ LLM 调用继续
    └→ 生成响应
    ↓
[LLM 调用后钩子执行]
    ├→ 钩子 1: 清理响应
    ├→ 钩子 2: 记录响应
    └→ 钩子 3: 更新指标
    ↓
返回最终响应
```

### 工具调用流程

```
代理需要执行工具
    ↓
[工具调用前钩子执行]
    ├→ 钩子 1: 检查工具是否允许
    ├→ 钩子 2: 验证输入
    └→ 钩子 3: 如需要请求审批
    ↓
如果任何钩子返回 False:
    ├→ 阻止工具执行
    └→ 返回错误信息
    ↓
如果所有钩子返回 True/None:
    ├→ 工具执行继续
    └→ 生成结果
    ↓
[工具调用后钩子执行]
    ├→ 钩子 1: 清理结果
    ├→ 钩子 2: 缓存结果
    └→ 钩子 3: 记录指标
    ↓
返回最终结果
```

## 钩子上下文对象

### LLMCallHookContext

提供对 LLM 执行状态的访问：

```python
class LLMCallHookContext:
    executor: CrewAgentExecutor  # 完整执行器访问
    messages: list               # 可变消息列表
    agent: Agent                 # 当前代理
    task: Task                   # 当前任务
    crew: Crew                   # 团队实例
    llm: BaseLLM                 # LLM 实例
    iterations: int              # 当前迭代次数
    response: str | None         # LLM 响应（钩子后）
```

### ToolCallHookContext

提供对工具执行状态的访问：

```python
class ToolCallHookContext:
    tool_name: str               # 被调用的工具
    tool_input: dict             # 可变输入参数
    tool: CrewStructuredTool     # 工具实例
    agent: Agent | None          # 执行的代理
    task: Task | None            # 当前任务
    crew: Crew | None            # 团队实例
    tool_result: str | None      # 工具结果（钩子后）
```

## 常见模式

### 安全和验证

```python
@before_tool_call
def safety_check(context):
    """阻止破坏性操作。"""
    dangerous = ['delete_file', 'drop_table', 'system_shutdown']
    if context.tool_name in dangerous:
        print(f"🛑 已阻止: {context.tool_name}")
        return False
    return None

@before_llm_call
def iteration_limit(context):
    """防止无限循环。"""
    if context.iterations > 15:
        print("⛔ 超过最大迭代次数")
        return False
    return None
```

### 人工循环

```python
@before_tool_call
def require_approval(context):
    """敏感操作需要审批。"""
    sensitive = ['send_email', 'make_payment', 'post_message']

    if context.tool_name in sensitive:
        response = context.request_human_input(
            prompt=f"批准 {context.tool_name}?",
            default_message="输入 'yes' 批准:"
        )

        if response.lower() != 'yes':
            return False

    return None
```

### 监控和分析

```python
from collections import defaultdict
import time

metrics = defaultdict(lambda: {'count': 0, 'total_time': 0})

@before_tool_call
def start_timer(context):
    context.tool_input['_start'] = time.time()
    return None

@after_tool_call
def track_metrics(context):
    start = context.tool_input.get('_start', time.time())
    duration = time.time() - start

    metrics[context.tool_name]['count'] += 1
    metrics[context.tool_name]['total_time'] += duration

    return None

# 查看指标
def print_metrics():
    for tool, data in metrics.items():
        avg = data['total_time'] / data['count']
        print(f"{tool}: {data['count']} 次调用, {avg:.2f}s 平均")
```

### 响应清理

```python
import re

@after_llm_call
def sanitize_llm_response(context):
    """从 LLM 响应中移除敏感数据。"""
    if not context.response:
        return None

    result = context.response
    result = re.sub(r'(api[_-]?key)["\']?\s*[:=]\s*["\']?[\w-]+',
                   r'\1: [已编辑]', result, flags=re.IGNORECASE)
    return result

@after_tool_call
def sanitize_tool_result(context):
    """从工具结果中移除敏感数据。"""
    if not context.tool_result:
        return None

    result = context.tool_result
    result = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
                   '[邮箱已编辑]', result)
    return result
```

## 钩子管理

### 清除所有钩子

```python
from crewai.hooks import clear_all_global_hooks

# 一次性清除所有钩子
result = clear_all_global_hooks()
print(f"清除了 {result['total']} 个钩子")
# 输出: {'llm_hooks': (2, 1), 'tool_hooks': (1, 2), 'total': (3, 3)}
```

### 清除特定钩子类型

```python
from crewai.hooks import (
    clear_before_llm_call_hooks,
    clear_after_llm_call_hooks,
    clear_before_tool_call_hooks,
    clear_after_tool_call_hooks
)

# 清除特定类型
llm_before_count = clear_before_llm_call_hooks()
tool_after_count = clear_after_tool_call_hooks()
```

### 注销单个钩子

```python
from crewai.hooks import (
    unregister_before_llm_call_hook,
    unregister_after_tool_call_hook
)

def my_hook(context):
    ...

# 注册
register_before_llm_call_hook(my_hook)

# 稍后，注销
success = unregister_before_llm_call_hook(my_hook)
print(f"已注销: {success}")
```

## 最佳实践

### 1. 保持钩子专注

每个钩子应该有单一、明确的职责：

```python
# ✅ 好的 - 职责专注
@before_tool_call
def validate_file_path(context):
    if context.tool_name == 'read_file':
        if '..' in context.tool_input.get('path', ''):
            return False
    return None

# ❌ 不好的 - 职责过多
@before_tool_call
def do_everything(context):
    # 验证 + 日志记录 + 指标 + 审批...
    ...
```

### 2. 优雅地处理错误

```python
@before_llm_call
def safe_hook(context):
    try:
        # 您的逻辑
        if some_condition:
            return False
    except Exception as e:
        print(f"钩子错误: {e}")
        return None  # 尽管出错仍允许执行
```

### 3. 原地修改上下文

```python
# ✅ 正确 - 原地修改
@before_llm_call
def add_context(context):
    context.messages.append({"role": "system", "content": "要简洁"})

# ❌ 错误 - 替换引用
@before_llm_call
def wrong_approach(context):
    context.messages = [{"role": "system", "content": "要简洁"}]
```

### 4. 使用类型提示

```python
from crewai.hooks import LLMCallHookContext, ToolCallHookContext

def my_llm_hook(context: LLMCallHookContext) -> bool | None:
    # IDE 自动补全和类型检查
    return None

def my_tool_hook(context: ToolCallHookContext) -> str | None:
    return None
```

### 5. 测试中清理

```python
import pytest
from crewai.hooks import clear_all_global_hooks

@pytest.fixture(autouse=True)
def clean_hooks():
    """每次测试前重置钩子。"""
    yield
    clear_all_global_hooks()
```

## 何时使用哪种钩子

### 使用 LLM 钩子当：
- 实现迭代限制
- 向提示添加上下文或安全准则
- 跟踪令牌使用和成本
- 清理或转换响应
- 为 LLM 调用实现审批门
- 调试提示/响应交互

### 使用工具钩子当：
- 阻止危险或破坏性操作
- 在执行前验证工具输入
- 为敏感操作实现审批门
- 缓存工具结果
- 跟踪工具使用和性能
- 清理工具输出
- 限制工具调用速率

### 两者都使用当：
构建需要监控所有代理操作的综合观察性、安全性或审批系统。

## 替代注册方法

### 程序化注册（高级）

用于动态钩子注册或当您需要程序化注册钩子时：

```python
from crewai.hooks import (
    register_before_llm_call_hook,
    register_after_tool_call_hook
)

def my_hook(context):
    return None

# 程序化注册
register_before_llm_call_hook(my_hook)

# 有用于:
# - 从配置加载钩子
# - 条件钩子注册
# - 插件系统
```

**注意：** 对于大多数用例，装饰器更简洁且更易维护。

## 性能考虑

1. **保持钩子快速**：钩子在每次调用时执行 - 避免繁重的计算
2. **尽可能缓存**：存储昂贵的验证或查找
3. **选择性强**：当不需要全局钩子时使用团队范围钩子
4. **监控钩子开销**：在生产环境中分析钩子执行时间
5. **延迟导入**：仅在需要时导入繁重的依赖项

## 调试钩子

### 启用调试日志

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

@before_llm_call
def debug_hook(context):
    logger.debug(f"LLM 调用: {context.agent.role}, 迭代 {context.iterations}")
    return None
```

### 钩子执行顺序

钩子按注册顺序执行。如果 before 钩子返回 `False`，后续钩子不执行：

```python
# 注册顺序很重要！
register_before_tool_call_hook(hook1)  # 首先执行
register_before_tool_call_hook(hook2)  # 第二执行
register_before_tool_call_hook(hook3)  # 第三执行

# 如果 hook2 返回 False:
# - hook1 已执行
# - hook2 已执行并返回 False
# - hook3 未执行
# - 工具调用被阻止
```

## 相关文档

- [LLM 调用钩子 →](/learn/llm-hooks) - 详细的 LLM 钩子文档
- [工具调用钩子 →](/learn/tool-hooks) - 详细的工具钩子文档
- [启动前后钩子 →](/learn/before-and-after-kickoff-hooks) - 团队生命周期钩子
- [人工循环 →](/learn/human-in-the-loop) - 人工输入模式

## 结论

执行钩子提供对代理运行时行为的强大控制。使用它们来实现安全护栏、审批工作流、全面监控和自定义业务逻辑。结合适当的错误处理、类型安全和性能考虑，钩子支持生产就绪、安全和可观察的代理系统。